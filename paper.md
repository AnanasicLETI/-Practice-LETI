# Сравнение различных модификаций линейного дискриминантного анализа в задаче верификации личности.
*Ключевые слова*: распознавание лиц, линейные гауссовские модели, вероятностный линейный дискриминантный анализ, факторный анализ, метод главных компонент.
## Аннотация 
Распознавание лиц в наше время остается открытой проблемой, которая не была решена с помощью существующих методов распознавания. В статье была проанализирована данная проблема с использованием недавно предложенного варианта вероятностного линейного дискриминантного анализа (ВЛДА). Также было выявлено, что модификации ВЛДА, которые регулярно используются в области верификации лиц, опираются на определенные допущения, которые не только приводят к упрощению модели, но и уменьшают вычислительную нагрузку на технику и улучшают показатели распознавания. 

## Введение
Распознавание лиц [2] представляет собой очень активную область исследований, привлекающую интерес все большего числа исследовательских групп со всего мира каждый год. Этот интерес подогревается огромным количеством областей развертывания, где применима технология распознавания лиц, а также потенциальной коммерческой ценностью этой технологии.

В ранних исследованиях данной области доминировали методы, основанные на изображениях лиц, которые не брали в учет такие факторы, как освещение, наклон головы и т.п. К таким методам относится метод главных компонент (МГК) [1], факторный анализ (ФА)[1] .

С прогрессом, достигнутым в области машинного обучения, исследователи начали отходить от простых проблем распознавания лиц и стали переходить к более реалистичным сценариям распознавания, когда изображения лиц были получены в различных условиях освещения и поз. Современные методы, такие как ВЛДА[3], пытаются смягчить эффекты вариаций изображения, вызванных различными влиятельными факторами, описывая лицо с помощью локальных векторов.     

Целью данной работы является изучение и сравнение модификаций вероятностного линейного дискриминантного анализа в задачах верификации личности по изображениям лиц.

Для выполнения данной цели необходимо решить следующие задачи:

1.Изучение модификаций вероятностного линейного дискриминантного анализа в задаче верификации личности и составление представление о данной области. 

2.Сравнение точности распознавания личности 

3.Определение наиболее эффективной модификации

## Обзор предметной области
Для обзора предметной области был осуществлен поиск линейных гауссовских моделей, которые используется для верификации личности по изображению лиц.

###### *Факторный анализ*
Факторный анализ является одним из самых простых и результативных методов в верификации личности. ФА позволяет выделить набор общих признаков, тем самым уменьшая  размерность данных.
###### *Метод главных компонент* 
Метод главных компонент часто используют в биометрии для определения важной информации. Самый распространённый вариант использования — анализ соответствий, что важно в задаче верификации личности. МГК определят пространство признаков, которое  уменьшает размерность оригинального пространства данных.
###### *Стандартный ВЛДА*
Стандартный вероятностный линейный дискриминантный анализ представляет собой вероятностную версию линейного дискриминантного анализа и был первоначально разработан для задачи надежного распознавания лиц. ВЛДА ищет такое преобразование изображений, которое бы минимизировало внутриклассовые и максимизировало межклассовые различия набора изображений. 

Определ как:

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;{\phi_{ij}}=\mu&space;&plus;&space;V{y_{ij}}&plus;U{x_{ij}}&plus;{\varepsilon_{ij}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;{\phi_{ij}}=\mu&space;&plus;&space;V{y_{i}}&plus;U{x_{ij}}&plus;{\varepsilon_{ij}}" title="\huge {\phi_{ij}}=\mu + V{y_{ij}}+U{x_{ij}}+{\varepsilon_{ij}}" /></a>                                                                                                           (1)

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;{y_{i}}&space;\sim&space;N(0,I)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;{y_{i}}&space;\sim&space;N(0,I)" title="\huge {y_{ij}} \sim N(0,I)" /></a>     (2)

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;{x_{ij}}&space;\sim&space;N(0,I)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;{x_{ij}}&space;\sim&space;N(0,I)" title="\huge {y_{ij}} \sim N(0,I)" /></a>    (3)

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;{\varepsilon&space;_{ij}}&space;\sim&space;N(0,\Lambda^{-1})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;{\varepsilon&space;_{ij}}&space;\sim&space;N(0,\Lambda^{-1})" title="\huge {\varepsilon _{ij}} \sim N(0,\Lambda^{-1})" /></a>                                                                      (4)

где <a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;\phi&space;\in\mathbb{R}^{D\times&space;P}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;\phi&space;\in\mathbb{R}^{D\times&space;P}" title="\huge \phi \in\mathbb{R}^{D\times P}" /></a> , <a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;U&space;\in\mathbb{R}^{D\times&space;M}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;U&space;\in\mathbb{R}^{D\times&space;M}" title="\huge U \in\mathbb{R}^{D\times M}" /></a> , <a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;V&space;\in\mathbb{R}^{D\times&space;P}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;V&space;\in\mathbb{R}^{D\times&space;P}" title="\huge V \in\mathbb{R}^{D\times P}" /></a>

<a href="https://www.codecogs.com/eqnedit.php?latex=\mu" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\mu" title="\mu" /></a> - глобальное среднее , <a href="https://www.codecogs.com/eqnedit.php?latex=\Lambda" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\Lambda" title="\Lambda" /></a> - диагональная матрица точности.



###### *Упрощенный ВЛДА*
Упрощенный вероятностный линейный дискриминантный анализ в отличие от стандартного ВЛДА позволяет использовать полные ковариационные матрицы вместо диагональных, снижая тем самым вычислительные затраты.
Определ как:

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;{\phi_{ij}}=\mu&space;&plus;&space;S{y_{ij}}&plus;{\varepsilon_{ij}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;{\phi_{ij}}=\mu&space;&plus;&space;S{y_{ij}}&plus;{\varepsilon_{ij}}" title="\huge {\phi_{ij}}=\mu + S{y_{i}}+{\varepsilon_{ij}}" /></a>(5)

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;{y_{i}}&space;\sim&space;N(0,I)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;{y_{i}}&space;\sim&space;N(0,I)" title="\huge {y_{ij}} \sim N(0,I)" /></a>(6)

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;{\varepsilon&space;_{ij}}&space;\sim&space;N(0,{\Lambda_{f}}^{-1}&space;)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;{\varepsilon&space;_{ij}}&space;\sim&space;N(0,{\Lambda_{f}}^{-1}&space;)" title="\huge {\varepsilon _{ij}} \sim N(0,\Lambda_^{-1} )" /></a>(7)

где <a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;\Lambda&space;_{f}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;\Lambda&space;_{f}" title="\huge \Lambda _{f}" /></a> - матрица полной точности.

###### *Двух-ковариационный ВЛДА*
Двух-ковариационный ВЛДА в отличие от двух предыдущих модификаций, больше не имеет подпространств с уменьшенной размерностью.

Определ как:

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;y_{i}&space;\sim&space;N(y_{i}|\mu,B^{-1})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;y_{i}&space;\sim&space;N(y_{i}|\mu,B^{-1})" title="\huge y_{i} \sim N(y_{i}|\mu,B^{-1})" /></a>(8)

<a href="https://www.codecogs.com/eqnedit.php?latex=\huge&space;\phi_{i}&space;|y_{i}&space;\sim&space;N(\phi_{i}|y_{i},W^{-1})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\huge&space;\phi_{i}&space;|y_{i}&space;\sim&space;N(\phi_{i}|y_{i},W^{-1})" title="\huge \phi_{i} |y_{i} \sim N(\phi_{i}|y_{i},W^{-1})" /></a>(9)  , 

где B и W - матрицы полной точности
### Критерии сравнения аналогов:
##### 1.	Вычислительные затраты
Размер ресурсов, используемых в данном процессе,таких как ОЗУ.
Данный критерий важен,так как с возрастанием вычислительных затрат,вычислительной мощности компьютера может быть недостаточно для решения задачи.
##### 2.	Добавление нового лица без переобучения 
Добавление нового эталонного лица в базу данных не требует полного переобучения классификатора.
Этот критерий важен,так как с меньшим количеством признаков уменьшается количество объектов для уверенного восстановления скрытых зависимостей в данных.
##### 3.	Процент распознавания лиц 
Процент совпадения показаний измерительного прибора с истинным значением измеряемой величины.

В данном случае имеется пара векторов (биометрических образцов), есть два возможных ответа:

1. ***оба вектора соответствуют одной личности***

2. ***вектора принадлежат разным личностям***



Таблица 1.Cравнение по критериям.

|                         | Большие вычислительные затраты | Добавление нового лица без переобучения|Процент распознавания лиц [4] |
| ----------------- | ----------------------------------------- | ------------------- | ------------------------------------ |
| Метод главных компонент  |  +  |+| 96| 
| Факторный анализ | - | -|95| 
| Стандартный ВЛДА | +| -|97|
| Упрощенный ВЛДА  | -| + |97| 
| Двух-ковариационный ВЛДА  | -|  +|97| 

## Выбор метода решения
Таким образом, каждый из приведенных выше методов, используемых в задаче верификации личности имеют свои достоинства и недостатки. Сравнительный анализ по трем критериям, представленный в таблице 1, показывает, что лучше всех с данной задачей справляются модификации вероятностного линейного дискриминантного анализа, так как по сравнению с другими аналогами они не требуют больших вычислительных затрат и переобучения классификатора с добавлением нового лица.

## Описание метода решения
##### Изучение структуры моделей	
Все скрытые переменные в формулировке ВЛДА (1) имеют гауссово 
распределение. Таким образом, распределение наблюдаемых переменных также является гауссовым. Можно сделать вывод, что структура у стандартного ВЛДА и его модификаций одинакова, единственное отличие это наличие ковариационных матриц, что в свою очередь только помогает снизить вычислительные затраты (9).

##### Расчет степеней свободы
Все три модели имеют одинаковую структуру, но их
распознавательные возможности различаются, так как они имеют разное число независимых параметров.

![Рис.1.Степени свободы для каждой модели.](https://github.com/AnanasicLETI/-Practice-LETI/blob/master/%D1%81%D1%82%D0%B5%D0%BF_%D1%81%D0%B2%D0%BE%D0%B1%D0%BE%D0%B4.jpg)
Рис.1.Степени свободы для каждой модели.

Здесь D - размерность вектора признаков ; P, M, L - число базисных векторов для подпространств соответствующих моделей.B_n  и W_n являются матрицами точности моделей.
	На рис.1 указаны степени свободы для каждой модели из которых видно следующее:

1.Когда L = D , упрощенная ВЛДА эквивалентна двух-ковариационной модели.

2. Когда P = D и M = D - 1, стандартная модель ВЛДА эквивалентна
двух-ковариационной модели.

3. Когда P = L и M = D - 1, стандартная модель ВЛДА эквивалентна упрощенной ВЛДА.

## Заключение
В результате выполнения данной работы  было проведено изучение и сравнение стандартной, упрощенной и двух-ковариационной модификаций вероятностного линейного дискриминантного анализа. Было выявлено, что стандартный ВЛДА является наиболее общей формулировкой и что при определенных конфигурациях он эквивалентен двум другим моделям с точки зрения распознавания. 

Результаты показали, что лучше использовать упрощенную версию вероятностного линейного дискриминантного анализа, т.к. процент распознавания лиц у данной модификации не хуже, чем у аналогов, данная модель не требует больших вычислительных затрат и переобучения классификатора при добавлении нового лица, а также при определенных конфигурациях может быть эквивалентна двух-ковариационной версии ВЛДА.

Несмотря на полученные результаты, проблема верификации личности все еще актуальна, что позволяет продолжить изучать данную область для нахождения наиболее эффективного решения.

## Источники
1. Мокеев А.В. Об эффективности распознавании лиц с помощью линейного
   дискриминантного анализа и метода главных компонент / Мокеев А.В.,
   Мокеев В.В.// Бизнес-информатика. – 2015г. – №3(33). – С. 44—54.
2. Линейный дискриминантный анализ//Распознавание. 
   URL:http://www.machinelearning.ru/wiki/index.php?title=Линейный_дискриминантный_анализ 
3. Face Recognition Using Simplified Probabilistic Linear Discriminant Analysis//Sage Journals.
   URL:https://journals.sagepub.com/doi/full/10.5772/52258
4. Labeled Faces in the Wild//Results.
   URL:http://vis-www.cs.umass.edu/lfw/results.html

